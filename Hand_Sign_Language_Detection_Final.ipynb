{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f314b055-6845-4107-aa21-7b43b3ecf615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in e:\\conda_envs\\py312\\lib\\site-packages (0.10.20)\n",
      "Requirement already satisfied: opencv-python in e:\\conda_envs\\py312\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: pandas in e:\\conda_envs\\py312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in e:\\conda_envs\\py312\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: pyttsx3 in e:\\conda_envs\\py312\\lib\\site-packages (2.98)\n",
      "Requirement already satisfied: absl-py in e:\\conda_envs\\py312\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in e:\\conda_envs\\py312\\lib\\site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in e:\\conda_envs\\py312\\lib\\site-packages (from mediapipe) (24.12.23)\n",
      "Requirement already satisfied: jax in e:\\conda_envs\\py312\\lib\\site-packages (from mediapipe) (0.5.0)\n",
      "Requirement already satisfied: jaxlib in e:\\conda_envs\\py312\\lib\\site-packages (from mediapipe) (0.5.0)\n",
      "Requirement already satisfied: matplotlib in e:\\conda_envs\\py312\\lib\\site-packages (from mediapipe) (3.10.0)\n",
      "Requirement already satisfied: numpy<2 in e:\\conda_envs\\py312\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in e:\\conda_envs\\py312\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in e:\\conda_envs\\py312\\lib\\site-packages (from mediapipe) (4.25.5)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in e:\\conda_envs\\py312\\lib\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in e:\\conda_envs\\py312\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\conda_envs\\py312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\conda_envs\\py312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\conda_envs\\py312\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\conda_envs\\py312\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\conda_envs\\py312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\conda_envs\\py312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: comtypes in e:\\conda_envs\\py312\\lib\\site-packages (from pyttsx3) (1.4.9)\n",
      "Requirement already satisfied: pypiwin32 in e:\\conda_envs\\py312\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in e:\\conda_envs\\py312\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Requirement already satisfied: six>=1.5 in e:\\conda_envs\\py312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in e:\\conda_envs\\py312\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in e:\\conda_envs\\py312\\lib\\site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in e:\\conda_envs\\py312\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\conda_envs\\py312\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\conda_envs\\py312\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\conda_envs\\py312\\lib\\site-packages (from matplotlib->mediapipe) (4.55.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\conda_envs\\py312\\lib\\site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\conda_envs\\py312\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in e:\\conda_envs\\py312\\lib\\site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\conda_envs\\py312\\lib\\site-packages (from matplotlib->mediapipe) (3.2.1)\n",
      "Requirement already satisfied: pycparser in e:\\conda_envs\\py312\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python pandas scikit-learn pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8da504b-2794-4193-8e6b-fcc32960bc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==4.25.3\n",
      "  Downloading protobuf-4.25.3-cp39-cp39-win_amd64.whl.metadata (541 bytes)\n",
      "Downloading protobuf-4.25.3-cp39-cp39-win_amd64.whl (413 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "Successfully installed protobuf-4.25.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==4.25.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96c2bba7-4001-45db-b16c-62bcd535f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pyttsx3\n",
    "import joblib\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c6ea1e-8338-46a8-96cf-54d18c7160e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8957e230-0592-44dd-a006-1a8efb07f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f08b3a1-8f05-41ca-8b10-b88adbccfe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks_G(image, results):\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0,255,0), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(0,255,0), thickness = 2,circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0,255,0), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(0,255,0), thickness = 2,circle_radius=1)\n",
    "                             )\n",
    "\n",
    "\n",
    "def draw_styled_landmarks_np_nf_B(image, results):\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,0), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,255), thickness = 2,circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,0), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,255), thickness = 2,circle_radius=1)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "444f13d3-d9f0-4f1f-abe1-378e02a1645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    rate = engine.getProperty('rate')\n",
    "    engine.setProperty('rate', 150)\n",
    "\n",
    "    #Setting the voice\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[1].id)\n",
    "\n",
    "    #Text input\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "729f7987-89ea-4e1f-aea6-648a0f074f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_L = joblib.load(\"MP_model_head.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89419be4-782d-416a-902d-94c38fc131e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_output(sign_list, sentence, sentence_out):\n",
    "    with open(\"multi_sign.csv\") as multisign_file:\n",
    "        sign_list = csv.reader(multisign_file)\n",
    "        for row in sign_list:\n",
    "            if sentence[-1] == row[-1]:\n",
    "                if sentence[-2] == row[-2]:\n",
    "                    sentence_out.append(row[0])\n",
    "                    break\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45b31841-8806-45ef-af33-110e58889193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(vidsource):\n",
    "    sentence = []\n",
    "    sentence_out = []\n",
    "    predictions = []\n",
    "    last_sign_list = []\n",
    "    one_sign_list = []\n",
    "    \n",
    "    # Minimum probability\n",
    "    threshold = 0.85\n",
    "    \n",
    "    # Minimum number of predictions for confirmation\n",
    "    pr = 3\n",
    "    \n",
    "    # For FPS calculation\n",
    "    pTime = 0\n",
    "    cTime = 0\n",
    "    \n",
    "    # Loading complex signs mechanism\n",
    "    with open(\"multi_sign.csv\") as multisign_file:\n",
    "        sign_list = csv.reader(multisign_file)\n",
    "        for row in sign_list:\n",
    "            last_sign_list.append(row[-1])\n",
    "    \n",
    "    # Loading simple signs\n",
    "    with open(\"single_sign.csv\") as singlesign_file:\n",
    "        singlesign_list = csv.reader(singlesign_file)\n",
    "        for row in singlesign_list:\n",
    "            one_sign_list.append(row[0])\n",
    "    \n",
    "    # Detecting from source of video feed\n",
    "    cap = cv2.VideoCapture(vidsource)\n",
    "    \n",
    "    # Set MediaPipe model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            # Read frame\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Make detections\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "            \n",
    "            # Draw for tracking\n",
    "            draw_styled_landmarks_np_nf_B(image, results)\n",
    "\n",
    "            # Extract landmarks\n",
    "            lh_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3))\n",
    "            rh_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3))\n",
    "            \n",
    "            # Initialize head with default values\n",
    "            head = list(np.zeros(3))  # A default zero array\n",
    "\n",
    "            # Check for pose landmarks and update head\n",
    "            if results.pose_landmarks:\n",
    "                for id, lm in enumerate(results.pose_landmarks.landmark):\n",
    "                    h, w, c = frame.shape\n",
    "                    cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "         \n",
    "                    if id == 0:\n",
    "                        if lm.visibility > 0.8:\n",
    "                            head = list(np.array([lm.x, lm.y, lm.z]))\n",
    "            \n",
    "            # Concatenate rows\n",
    "            row = lh_row + rh_row + head\n",
    "\n",
    "            # Make Detections\n",
    "            X = pd.DataFrame([row])\n",
    "            sign_class = model_L.predict(X)[0]\n",
    "            sign_prob = model_L.predict_proba(X)[0]\n",
    "\n",
    "            # Sentence Logic\n",
    "            if sign_prob[np.argmax(sign_prob)] > threshold:\n",
    "                predictions.append(sign_class)\n",
    "\n",
    "                if predictions[-pr:] == [sign_class] * pr:\n",
    "                    if len(sentence) > 0:\n",
    "                        if sign_class != sentence[-1]:\n",
    "                            sentence.append(sign_class)\n",
    "                            draw_styled_landmarks_G(image, results)\n",
    "                            \n",
    "                            if sentence[-1] in last_sign_list:\n",
    "                                sign_output(sign_list, sentence, sentence_out)\n",
    "                            \n",
    "                            if sentence[-1] in one_sign_list:\n",
    "                                sentence_out.append(sign_class)\n",
    "                    else:\n",
    "                        sentence.append(sign_class)\n",
    "                        draw_styled_landmarks_np_nf_B(image, results)\n",
    "                        if sentence[-1] in one_sign_list:\n",
    "                            sentence_out.append(sign_class)\n",
    "\n",
    "\n",
    "                    \n",
    "            if len(sentence_out) > 6:\n",
    "                sentence_out = sentence_out[-6:]\n",
    "            if len(sentence) > 6:\n",
    "                sentence = sentence[:-5]\n",
    "            \n",
    "            if sentence_out == \"Hello\":\n",
    "                sentence_out = \"Kem Chho?\"\n",
    "            \n",
    "            cv2.rectangle(image, (0, 0), (640, 40), (0, 0, 0), -1)\n",
    "            cv2.putText(image, ' '.join(sentence), (3, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            \n",
    "            cv2.rectangle(image, (0, 80), (640, 40), (255, 0, 0), -1)\n",
    "            cv2.putText(image, ' '.join(sentence_out), (3, 70),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "\n",
    "            # FPS\n",
    "            cTime = time.time()\n",
    "            fps = 1 / (cTime - pTime)\n",
    "            pTime = cTime\n",
    "\n",
    "            cv2.putText(image, \"fps\", (5, 415), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 0), 2)\n",
    "            cv2.putText(image, str(int(fps)), (10, 460), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 0), 5)\n",
    "\n",
    "            # Show to screen\n",
    "            # cv2.smartresize(image, 700, 700)\n",
    "            cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "            # Break loop\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa4309f7-6243-43c8-8e2d-1e1e22a27080",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a802e2e5-5f06-4a6b-a7b3-53ce9de01272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a102d75-6165-44a0-a461-06d69575e81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc3bb2-b76d-4f16-bfdf-9c7ee2152a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9162f3c-ebda-4173-b772-84733b01474c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa2068d-1ac1-468b-b628-6253159862b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c51743-1750-4269-9034-57c098190e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1c67b-b47a-4b71-847a-c6ec281cbb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b7bac3-6efc-4e22-945e-9faa03e12604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a803b005-0d61-47ea-99ba-4df1903ecb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a34dd-38ae-435b-98f2-b23691a80124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce8bff-001b-4006-89b2-4eacf8a26a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c044f3-4815-41b4-a24b-a07381e5f6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83e1a7-dabf-4a8e-b553-638c68d74e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc0a9d-37ef-4466-b10e-8b7578141a21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
